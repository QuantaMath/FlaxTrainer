{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "import flax.linen as nn\n",
    "\n",
    "import jax\n",
    "import jax.numpy as nn\n",
    "from typing import Any, Sequence, Optional, Tuple, Iterator, Dict, Callable, Union\n",
    "\n",
    "from jax import random, grad, value_and_grad, jit, vmap\n",
    "\n",
    "from models import AutoEncoder, MLPBlock\n",
    "\n",
    "\n",
    "from jax import numpy as jnp\n",
    "import jax\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "def create_data_loaders(*datasets : Sequence[data.Dataset],\n",
    "                        train : Union[bool, Sequence[bool]] = True,\n",
    "                        batch_size : int = 128,\n",
    "                        num_workers : int = 4,\n",
    "                        seed : int = 42):\n",
    "    \"\"\"\n",
    "    Creates data loaders used in JAX for a set of datasets.\n",
    "\n",
    "    Args:\n",
    "      datasets: Datasets for which data loaders are created.\n",
    "      train: Sequence indicating which datasets are used for\n",
    "        training and which not. If single bool, the same value\n",
    "        is used for all datasets.\n",
    "      batch_size: Batch size to use in the data loaders.\n",
    "      num_workers: Number of workers for each dataset.\n",
    "      seed: Seed to initialize the workers and shuffling with.\n",
    "    \"\"\"\n",
    "    loaders = []\n",
    "    if not isinstance(train, (list, tuple)):\n",
    "        train = [train for _ in datasets]\n",
    "    for dataset, is_train in zip(datasets, train):\n",
    "        loader = data.DataLoader(dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=is_train,\n",
    "                                 drop_last=is_train,\n",
    "                                 collate_fn=numpy_collate,\n",
    "                                 num_workers=num_workers,\n",
    "                                 persistent_workers=is_train,\n",
    "                                 generator=torch.Generator().manual_seed(seed))\n",
    "        loaders.append(loader)\n",
    "    return loaders\n",
    "\n",
    "\n",
    "\n",
    "def target_function(x):\n",
    "    return np.sin(x * 3.0)\n",
    "\n",
    "class RegressionDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, num_points, num_feat, seed):\n",
    "        super().__init__()\n",
    "        rng = np.random.default_rng(seed)\n",
    "        self.x = rng.uniform(low=-1.0, high=1.0, size=(num_points, num_feat))\n",
    "        self.y = target_function(self.x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx:idx+1], self.y[idx:idx+1]\n",
    "\n",
    "train_set = RegressionDataset(num_points=1000, num_feat=40, seed=42)\n",
    "val_set = RegressionDataset(num_points=200, num_feat=40, seed=43)\n",
    "test_set = RegressionDataset(num_points=500, num_feat=40, seed=44)\n",
    "train_loader, val_loader, test_loader = create_data_loaders(train_set, val_set, test_set,\n",
    "                                                            train=[True, False, False],\n",
    "                                                            batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 40\n",
    "latent_size = 20\n",
    "encoder = MLPBlock([1024,1024,512,512,512,512,128, 64], latent_size, hidden_activation='sigmoid')\n",
    "bottleneck = MLPBlock([64, 64, 32, 32, 16, 16], latent_size, hidden_activation='relu')\n",
    "decoder = MLPBlock([64, 128,512, 512, 512, 512, 1024, 1024], input_size, hidden_activation='tanh')\n",
    "\n",
    "autoencoder = AutoEncoder(encoder, decoder, bottleneck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlaxTrainer.trainer import TrainerModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainerModule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/vae/MLP Autoencoder.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/vae/MLP%20Autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mTrainAutoEncoder\u001b[39;00m(TrainerModule):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/vae/MLP%20Autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/vae/MLP%20Autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                  \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/vae/MLP%20Autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrainerModule' is not defined"
     ]
    }
   ],
   "source": [
    "class TrainAutoEncoder(TrainerModule):\n",
    "    def __init__(self,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def create_functions(self):\n",
    "        def mse_loss(params, apply_fn, batch):\n",
    "            x, _ = batch\n",
    "            print(x)\n",
    "            pred = apply_fn({'params': params}, x)\n",
    "            loss = ((pred - x) ** 2).mean()\n",
    "            return loss\n",
    "    \n",
    "        def train_step(state, batch):\n",
    "            loss_fn = lambda params: mse_loss(params, state.apply_fn, batch)\n",
    "            loss, grads = jax.value_and_grad(loss_fn)(state.params)\n",
    "            state = state.apply_gradients(grads=grads)\n",
    "            metrics = {'loss': loss}\n",
    "            return state, metrics\n",
    "        \n",
    "        def eval_step(state, batch):\n",
    "            loss = mse_loss(state.params, state.apply_fn, batch)\n",
    "            return {'loss': loss}\n",
    "\n",
    "        return train_step, eval_step\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainAutoEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/vae/MLP Autoencoder.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/vae/MLP%20Autoencoder.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m CHECKPOINT_PATH \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./saved_models/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/vae/MLP%20Autoencoder.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# TODO: Solve conflict of check_val_every_n_epoch and num_epochs\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/vae/MLP%20Autoencoder.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#mock = mockedcallback.MockedCallback(stop_train=False)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/vae/MLP%20Autoencoder.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m trainer \u001b[39m=\u001b[39m TrainAutoEncoder(optimizer_hparams\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m4e-3\u001b[39m},\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/vae/MLP%20Autoencoder.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                             logger_params\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mbase_log_dir\u001b[39m\u001b[39m'\u001b[39m: CHECKPOINT_PATH},                           \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/vae/MLP%20Autoencoder.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                             check_val_every_n_epoch\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrainAutoEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = \"./saved_models/\"\n",
    "# TODO: Solve conflict of check_val_every_n_epoch and num_epochs\n",
    "#mock = mockedcallback.MockedCallback(stop_train=False)\n",
    "trainer = TrainAutoEncoder(optimizer_hparams={'lr': 4e-3},\n",
    "                            logger_params={'base_log_dir': CHECKPOINT_PATH},                           \n",
    "                            check_val_every_n_epoch=5)\n",
    " #                           callbacks=[mock])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: ./saved_models/AutoEncoder/\n",
      "/home/gholamhossin/local/labs/.labs/lib/python3.10/site-packages/flax/linen/summary.py:406: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  leaves = jax.tree_leaves(pytree)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                          AutoEncoder Summary                           </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path               </span>┃<span style=\"font-weight: bold\"> outputs            </span>┃<span style=\"font-weight: bold\"> params                     </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs             │ - <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float64</span>[64,1,40] │                            │\n",
       "│                    │ - train: True      │                            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ Dense_0            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,40]   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[40,40]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">1,600 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(6.4 KB)</span>             │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_0 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,64]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]          │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[20,64]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">1,344 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(5.4 KB)</span>             │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_1 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,64]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]          │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,64]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">4,160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(16.6 KB)</span>            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_2 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,32]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]          │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,32]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">2,080 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(8.3 KB)</span>             │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_3 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,32]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]          │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32,32]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">1,056 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 KB)</span>             │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_4 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,16]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16]          │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32,16]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">528 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.1 KB)</span>               │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_5 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,16]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16]          │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,16]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">272 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.1 KB)</span>               │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_6 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,20]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[20]          │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,20]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">340 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.4 KB)</span>               │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,20]   │                            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_0    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,64]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]          │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[20,64]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">1,344 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(5.4 KB)</span>             │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_1    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,128]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128]         │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,128]    │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">8,320 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(33.3 KB)</span>            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_2    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,512]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">66,048 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(264.2 KB)</span>          │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_3    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,512]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">262,656 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.1 MB)</span>           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_4    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,512]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">262,656 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.1 MB)</span>           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_5    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,512]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">262,656 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.1 MB)</span>           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_6    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,1024] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1024]        │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1024]  │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">525,312 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.1 MB)</span>           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_7    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,1024] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1024]        │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1024,1024] │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">1,049,600 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_8    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,40]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[40]          │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1024,40]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">41,000 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(164.0 KB)</span>          │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,40]   │                            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_0    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,1024] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1024]        │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[40,1024]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">41,984 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(167.9 KB)</span>          │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_1    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,1024] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1024]        │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1024,1024] │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">1,049,600 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_2    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,512]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1024,512]  │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">524,800 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.1 MB)</span>           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_3    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,512]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">262,656 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.1 MB)</span>           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_4    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,512]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">262,656 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.1 MB)</span>           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_5    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,512]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">262,656 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.1 MB)</span>           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_6    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,128]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128]         │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,128]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">65,664 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(262.7 KB)</span>          │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_7    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,64]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]          │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128,64]    │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">8,256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(33.0 KB)</span>            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_8    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,20]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[20]          │\n",
       "│                    │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,20]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ <span style=\"font-weight: bold\">1,300 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(5.2 KB)</span>             │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,20]   │                            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ AutoEncoder        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1,40]   │                            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">                    </span>│<span style=\"font-weight: bold\">              Total </span>│<span style=\"font-weight: bold\"> 4,970,544 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(19.9 MB)</span><span style=\"font-weight: bold\">        </span>│\n",
       "└────────────────────┴────────────────────┴────────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                        </span>\n",
       "<span style=\"font-weight: bold\">                 Total Parameters: 4,970,544 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(19.9 MB)</span><span style=\"font-weight: bold\">                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                          AutoEncoder Summary                           \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs             │ - \u001b[2mfloat64\u001b[0m[64,1,40] │                            │\n",
       "│                    │ - train: True      │                            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ Dense_0            │ \u001b[2mfloat32\u001b[0m[64,1,40]   │ kernel: \u001b[2mfloat32\u001b[0m[40,40]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m1,600 \u001b[0m\u001b[1;2m(6.4 KB)\u001b[0m             │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_0 │ \u001b[2mfloat32\u001b[0m[64,1,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]          │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[20,64]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m1,344 \u001b[0m\u001b[1;2m(5.4 KB)\u001b[0m             │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_1 │ \u001b[2mfloat32\u001b[0m[64,1,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]          │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[64,64]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m4,160 \u001b[0m\u001b[1;2m(16.6 KB)\u001b[0m            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_2 │ \u001b[2mfloat32\u001b[0m[64,1,32]   │ bias: \u001b[2mfloat32\u001b[0m[32]          │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[64,32]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m2,080 \u001b[0m\u001b[1;2m(8.3 KB)\u001b[0m             │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_3 │ \u001b[2mfloat32\u001b[0m[64,1,32]   │ bias: \u001b[2mfloat32\u001b[0m[32]          │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[32,32]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m1,056 \u001b[0m\u001b[1;2m(4.2 KB)\u001b[0m             │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_4 │ \u001b[2mfloat32\u001b[0m[64,1,16]   │ bias: \u001b[2mfloat32\u001b[0m[16]          │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[32,16]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m528 \u001b[0m\u001b[1;2m(2.1 KB)\u001b[0m               │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_5 │ \u001b[2mfloat32\u001b[0m[64,1,16]   │ bias: \u001b[2mfloat32\u001b[0m[16]          │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[16,16]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m272 \u001b[0m\u001b[1;2m(1.1 KB)\u001b[0m               │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck/Dense_6 │ \u001b[2mfloat32\u001b[0m[64,1,20]   │ bias: \u001b[2mfloat32\u001b[0m[20]          │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[16,20]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m340 \u001b[0m\u001b[1;2m(1.4 KB)\u001b[0m               │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ bottleneck         │ \u001b[2mfloat32\u001b[0m[64,1,20]   │                            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_0    │ \u001b[2mfloat32\u001b[0m[64,1,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]          │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[20,64]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m1,344 \u001b[0m\u001b[1;2m(5.4 KB)\u001b[0m             │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_1    │ \u001b[2mfloat32\u001b[0m[64,1,128]  │ bias: \u001b[2mfloat32\u001b[0m[128]         │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[64,128]    │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m8,320 \u001b[0m\u001b[1;2m(33.3 KB)\u001b[0m            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_2    │ \u001b[2mfloat32\u001b[0m[64,1,512]  │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[128,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m66,048 \u001b[0m\u001b[1;2m(264.2 KB)\u001b[0m          │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_3    │ \u001b[2mfloat32\u001b[0m[64,1,512]  │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[512,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m262,656 \u001b[0m\u001b[1;2m(1.1 MB)\u001b[0m           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_4    │ \u001b[2mfloat32\u001b[0m[64,1,512]  │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[512,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m262,656 \u001b[0m\u001b[1;2m(1.1 MB)\u001b[0m           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_5    │ \u001b[2mfloat32\u001b[0m[64,1,512]  │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[512,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m262,656 \u001b[0m\u001b[1;2m(1.1 MB)\u001b[0m           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_6    │ \u001b[2mfloat32\u001b[0m[64,1,1024] │ bias: \u001b[2mfloat32\u001b[0m[1024]        │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[512,1024]  │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m525,312 \u001b[0m\u001b[1;2m(2.1 MB)\u001b[0m           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_7    │ \u001b[2mfloat32\u001b[0m[64,1,1024] │ bias: \u001b[2mfloat32\u001b[0m[1024]        │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[1024,1024] │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m1,049,600 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder/Dense_8    │ \u001b[2mfloat32\u001b[0m[64,1,40]   │ bias: \u001b[2mfloat32\u001b[0m[40]          │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[1024,40]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m41,000 \u001b[0m\u001b[1;2m(164.0 KB)\u001b[0m          │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ decoder            │ \u001b[2mfloat32\u001b[0m[64,1,40]   │                            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_0    │ \u001b[2mfloat32\u001b[0m[64,1,1024] │ bias: \u001b[2mfloat32\u001b[0m[1024]        │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[40,1024]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m41,984 \u001b[0m\u001b[1;2m(167.9 KB)\u001b[0m          │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_1    │ \u001b[2mfloat32\u001b[0m[64,1,1024] │ bias: \u001b[2mfloat32\u001b[0m[1024]        │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[1024,1024] │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m1,049,600 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_2    │ \u001b[2mfloat32\u001b[0m[64,1,512]  │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[1024,512]  │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m524,800 \u001b[0m\u001b[1;2m(2.1 MB)\u001b[0m           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_3    │ \u001b[2mfloat32\u001b[0m[64,1,512]  │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[512,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m262,656 \u001b[0m\u001b[1;2m(1.1 MB)\u001b[0m           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_4    │ \u001b[2mfloat32\u001b[0m[64,1,512]  │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[512,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m262,656 \u001b[0m\u001b[1;2m(1.1 MB)\u001b[0m           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_5    │ \u001b[2mfloat32\u001b[0m[64,1,512]  │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[512,512]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m262,656 \u001b[0m\u001b[1;2m(1.1 MB)\u001b[0m           │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_6    │ \u001b[2mfloat32\u001b[0m[64,1,128]  │ bias: \u001b[2mfloat32\u001b[0m[128]         │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[512,128]   │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m65,664 \u001b[0m\u001b[1;2m(262.7 KB)\u001b[0m          │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_7    │ \u001b[2mfloat32\u001b[0m[64,1,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]          │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[128,64]    │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m8,256 \u001b[0m\u001b[1;2m(33.0 KB)\u001b[0m            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder/Dense_8    │ \u001b[2mfloat32\u001b[0m[64,1,20]   │ bias: \u001b[2mfloat32\u001b[0m[20]          │\n",
       "│                    │                    │ kernel: \u001b[2mfloat32\u001b[0m[64,20]     │\n",
       "│                    │                    │                            │\n",
       "│                    │                    │ \u001b[1m1,300 \u001b[0m\u001b[1;2m(5.2 KB)\u001b[0m             │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ encoder            │ \u001b[2mfloat32\u001b[0m[64,1,20]   │                            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│ AutoEncoder        │ \u001b[2mfloat32\u001b[0m[64,1,40]   │                            │\n",
       "├────────────────────┼────────────────────┼────────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m                  \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m4,970,544 \u001b[0m\u001b[1;2m(19.9 MB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
       "└────────────────────┴────────────────────┴────────────────────────────┘\n",
       "\u001b[1m                                                                        \u001b[0m\n",
       "\u001b[1m                 Total Parameters: 4,970,544 \u001b[0m\u001b[1;2m(19.9 MB)\u001b[0m\u001b[1m                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = trainer.init_model(\n",
    "    autoencoder,exmp_input=next(iter(train_loader))[0:1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 100/100 [00:18<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.33323097229003906\n",
      "Validation loss: 0.33861681818962097\n",
      "Test loss: 0.3346109688282013\n"
     ]
    }
   ],
   "source": [
    "metrics, state = trainer.train_model(\n",
    "    autoencoder,\n",
    "    state,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=100\n",
    ")\n",
    "\n",
    "#print(state)\n",
    "print(f'Training loss: {metrics[\"train/loss\"]}')\n",
    "print(f'Validation loss: {metrics[\"val/loss\"]}')\n",
    "print(f'Test loss: {metrics[\"test/loss\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[-2.9340668 ,  0.9017485 , -1.5255569 , ...,  4.91492   ,\n",
       "                2.6670747 , -0.73887753]],\n",
       "\n",
       "             [[-2.9340687 ,  0.90174896, -1.525558  , ...,  4.9149218 ,\n",
       "                2.6670752 , -0.73887813]],\n",
       "\n",
       "             [[-2.9340699 ,  0.90174943, -1.525559  , ...,  4.9149237 ,\n",
       "                2.6670752 , -0.7388786 ]],\n",
       "\n",
       "             ...,\n",
       "\n",
       "             [[-2.9340696 ,  0.9017494 , -1.5255587 , ...,  4.9149227 ,\n",
       "                2.6670754 , -0.73887855]],\n",
       "\n",
       "             [[-2.9340684 ,  0.9017489 , -1.5255578 , ...,  4.9149218 ,\n",
       "                2.667075  , -0.73887783]],\n",
       "\n",
       "             [[-2.9340703 ,  0.90174955, -1.5255591 , ...,  4.9149237 ,\n",
       "                2.6670756 , -0.73887867]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = autoencoder.encoder.apply({'params':state.params['encoder']}, next(iter(train_loader))[0])\n",
    "autoencoder.decoder.apply({'params':state.params['decoder']}, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.labs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7c17e30e529363162b4f2bd4620f627c628f84c34e1cd85cef9b92e26a024c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
