{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "nn = flax.linen\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, value_and_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  \"\"\"A simple CNN model.\"\"\"\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x, **kwargs):\n",
    "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    x = x.reshape((x.shape[0], -1))  # flatten\n",
    "    x = nn.Dense(features=256)(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.Dense(features=10)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FashionMNIST, CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from typing import Sequence, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Data mean [0.49139968 0.48215841 0.44653091]\n",
      "Data std [0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CIFAR10(root='data', train=True, download=True)\n",
    "DATA_MEANS = (train_dataset.data / 255.0).mean(axis=(0,1,2))\n",
    "DATA_STD = (train_dataset.data / 255.0).std(axis=(0,1,2))\n",
    "print(\"Data mean\", DATA_MEANS)\n",
    "print(\"Data std\", DATA_STD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gholamhossin/local/labs/.labs/lib/python3.10/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# Transformations applied on each image => bring them into a numpy array\n",
    "def image_to_numpy(img):\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = (img / 255. - DATA_MEANS) / DATA_STD\n",
    "    return img\n",
    "\n",
    "# We need to stack the batch elements\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "\n",
    "test_transform = image_to_numpy\n",
    "# For training, we add some augmentation. Networks are too powerful and would overfit.\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
    "                                      image_to_numpy\n",
    "                                     ])\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "# We need to do a little trick because the validation set should not use the augmentation.\n",
    "train_dataset = CIFAR10(root='data' , train=True, transform=train_transform, download=True)\n",
    "val_dataset = CIFAR10(root='data', train=True, transform=test_transform, download=True)\n",
    "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000], generator=torch.Generator().manual_seed(42))\n",
    "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Loading the test set\n",
    "test_set = CIFAR10(root='data', train=False, transform=test_transform, download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for training and validation\n",
    "train_loader = data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=numpy_collate,\n",
    "    num_workers=32,\n",
    "    persistent_workers=True,\n",
    "    generator=torch.Generator().manual_seed(1024))\n",
    "val_loader   = data.DataLoader(val_set,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=numpy_collate,\n",
    "    num_workers=8,\n",
    "    persistent_workers=True,\n",
    "    generator=torch.Generator().manual_seed(1024))\n",
    "\n",
    "test_loader  = data.DataLoader(test_set,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=numpy_collate,\n",
    "    num_workers=8,\n",
    "    persistent_workers=True,\n",
    "    generator=torch.Generator().manual_seed(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch mean [-0.12891286 -0.22238259 -0.19784406]\n",
      "Batch std [0.99327482 1.01667114 0.98516537]\n"
     ]
    }
   ],
   "source": [
    "imgs, _ = next(iter(train_loader))\n",
    "print(\"Batch mean\", imgs.mean(axis=(0,1,2)))\n",
    "print(\"Batch std\", imgs.std(axis=(0,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flax not found, run 'pip install --upgrade git+https://github.com/google/flax.git'\n"
     ]
    }
   ],
   "source": [
    "from FlaxTrainer.trainer import TrainerModule\n",
    "from FlaxTrainer.trainstates import TrainState\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnnTrainer(TrainerModule):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def create_functions(self):\n",
    "        def cross_entropy_loss(params, apply_fn, batch):\n",
    "            x, y = batch\n",
    "            y = jax.nn.one_hot(y, num_classes=10)\n",
    "            logit = apply_fn({'params':params}, x)\n",
    "            loss = optax.softmax_cross_entropy(logits=logit , labels=y).mean()\n",
    "            return loss\n",
    "    \n",
    "        def train_step(state, batch):\n",
    "            loss_fn = lambda params: cross_entropy_loss(params, state.apply_fn, batch)\n",
    "            loss, grads = jax.value_and_grad(loss_fn)(state.params)\n",
    "            state = state.apply_gradients(grads=grads)\n",
    "            metrics = {'loss': loss}\n",
    "            return state, metrics\n",
    "        \n",
    "        def eval_step(state, batch):\n",
    "            loss = cross_entropy_loss(state.params, state.apply_fn, batch)\n",
    "            return {'loss': loss}\n",
    "\n",
    "        return train_step, eval_step\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = CNN()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"./saved_models/\"\n",
    "# TODO: Solve conflict of check_val_every_n_epoch and num_epochs\n",
    "#mock = mockedcallback.MockedCallback(stop_train=False)\n",
    "trainer = cnnTrainer(optimizer_hparams={'lr': 4e-3},\n",
    "                            logger_params={'base_log_dir': CHECKPOINT_PATH},                           \n",
    "                            check_val_every_n_epoch=5,\n",
    "                            enable_progress_bar=True)\n",
    " #                           callbacks=[mock])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                          CNN Summary                          </span>\n",
       "┏━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path    </span>┃<span style=\"font-weight: bold\"> outputs              </span>┃<span style=\"font-weight: bold\"> params                     </span>┃\n",
       "┡━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs  │ - <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float64</span>[8,32,32,3] │                            │\n",
       "│         │ - train: True        │                            │\n",
       "├─────────┼──────────────────────┼────────────────────────────┤\n",
       "│ Conv_0  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,32,32,32]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]          │\n",
       "│         │                      │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[3,3,3,32]  │\n",
       "│         │                      │                            │\n",
       "│         │                      │ <span style=\"font-weight: bold\">896 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(3.6 KB)</span>               │\n",
       "├─────────┼──────────────────────┼────────────────────────────┤\n",
       "│ Conv_1  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,16,16,64]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]          │\n",
       "│         │                      │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[3,3,32,64] │\n",
       "│         │                      │                            │\n",
       "│         │                      │ <span style=\"font-weight: bold\">18,496 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(74.0 KB)</span>           │\n",
       "├─────────┼──────────────────────┼────────────────────────────┤\n",
       "│ Dense_0 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,256]       │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[256]         │\n",
       "│         │                      │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4096,256]  │\n",
       "│         │                      │                            │\n",
       "│         │                      │ <span style=\"font-weight: bold\">1,048,832 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├─────────┼──────────────────────┼────────────────────────────┤\n",
       "│ Dense_1 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,10]        │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10]          │\n",
       "│         │                      │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[256,10]    │\n",
       "│         │                      │                            │\n",
       "│         │                      │ <span style=\"font-weight: bold\">2,570 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(10.3 KB)</span>            │\n",
       "├─────────┼──────────────────────┼────────────────────────────┤\n",
       "│ CNN     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,10]        │                            │\n",
       "├─────────┼──────────────────────┼────────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">         </span>│<span style=\"font-weight: bold\">                Total </span>│<span style=\"font-weight: bold\"> 1,070,794 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.3 MB)</span><span style=\"font-weight: bold\">         </span>│\n",
       "└─────────┴──────────────────────┴────────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                               </span>\n",
       "<span style=\"font-weight: bold\">             Total Parameters: 1,070,794 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.3 MB)</span><span style=\"font-weight: bold\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                          CNN Summary                          \u001b[0m\n",
       "┏━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs  │ - \u001b[2mfloat64\u001b[0m[8,32,32,3] │                            │\n",
       "│         │ - train: True        │                            │\n",
       "├─────────┼──────────────────────┼────────────────────────────┤\n",
       "│ Conv_0  │ \u001b[2mfloat32\u001b[0m[8,32,32,32]  │ bias: \u001b[2mfloat32\u001b[0m[32]          │\n",
       "│         │                      │ kernel: \u001b[2mfloat32\u001b[0m[3,3,3,32]  │\n",
       "│         │                      │                            │\n",
       "│         │                      │ \u001b[1m896 \u001b[0m\u001b[1;2m(3.6 KB)\u001b[0m               │\n",
       "├─────────┼──────────────────────┼────────────────────────────┤\n",
       "│ Conv_1  │ \u001b[2mfloat32\u001b[0m[8,16,16,64]  │ bias: \u001b[2mfloat32\u001b[0m[64]          │\n",
       "│         │                      │ kernel: \u001b[2mfloat32\u001b[0m[3,3,32,64] │\n",
       "│         │                      │                            │\n",
       "│         │                      │ \u001b[1m18,496 \u001b[0m\u001b[1;2m(74.0 KB)\u001b[0m           │\n",
       "├─────────┼──────────────────────┼────────────────────────────┤\n",
       "│ Dense_0 │ \u001b[2mfloat32\u001b[0m[8,256]       │ bias: \u001b[2mfloat32\u001b[0m[256]         │\n",
       "│         │                      │ kernel: \u001b[2mfloat32\u001b[0m[4096,256]  │\n",
       "│         │                      │                            │\n",
       "│         │                      │ \u001b[1m1,048,832 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├─────────┼──────────────────────┼────────────────────────────┤\n",
       "│ Dense_1 │ \u001b[2mfloat32\u001b[0m[8,10]        │ bias: \u001b[2mfloat32\u001b[0m[10]          │\n",
       "│         │                      │ kernel: \u001b[2mfloat32\u001b[0m[256,10]    │\n",
       "│         │                      │                            │\n",
       "│         │                      │ \u001b[1m2,570 \u001b[0m\u001b[1;2m(10.3 KB)\u001b[0m            │\n",
       "├─────────┼──────────────────────┼────────────────────────────┤\n",
       "│ CNN     │ \u001b[2mfloat32\u001b[0m[8,10]        │                            │\n",
       "├─────────┼──────────────────────┼────────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m               Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m1,070,794 \u001b[0m\u001b[1;2m(4.3 MB)\u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0m│\n",
       "└─────────┴──────────────────────┴────────────────────────────┘\n",
       "\u001b[1m                                                               \u001b[0m\n",
       "\u001b[1m             Total Parameters: 1,070,794 \u001b[0m\u001b[1;2m(4.3 MB)\u001b[0m\u001b[1m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = trainer.init_model(\n",
    "    model=model,exmp_input=next(iter(train_loader))[0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = model.apply({'params': state.params}, next(iter(train_loader))[0])\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   4%|▍         | 4/100 [00:53<21:35, 13.50s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'checkpoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain_model(model, state, train_loader\u001b[39m=\u001b[39;49mtrain_loader, val_loader\u001b[39m=\u001b[39;49mval_loader, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "File \u001b[0;32m~/local/labs/.labs/lib/python3.10/site-packages/FlaxTrainer/trainer.py:424\u001b[0m, in \u001b[0;36mTrainerModule.train_model\u001b[0;34m(self, model, state, train_loader, val_loader, test_loader, num_epochs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             best_eval_metrics \u001b[39m=\u001b[39m eval_metrics\n\u001b[1;32m    423\u001b[0m             best_eval_metrics\u001b[39m.\u001b[39mupdate(train_metrics)\n\u001b[0;32m--> 424\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_model(new_state, step\u001b[39m=\u001b[39;49mepoch_idx)\n\u001b[1;32m    425\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_metrics(\u001b[39m'\u001b[39m\u001b[39mbest_eval\u001b[39m\u001b[39m'\u001b[39m, eval_metrics)\n\u001b[1;32m    426\u001b[0m \u001b[39m# Test best model if possible\u001b[39;00m\n",
      "File \u001b[0;32m~/local/labs/.labs/lib/python3.10/site-packages/FlaxTrainer/trainer.py:609\u001b[0m, in \u001b[0;36mTrainerModule.save_model\u001b[0;34m(self, state, step)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39mSave current training state at certain training iteration. Only the model\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[39mparameters and batch statistics are saved to reduce memory footprint. To\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[39m  step: Index of the step to save the model at, e.g. epoch.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[39m#[callback.on_save_checkpoint() for callback in callbacks]\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m checkpoints\u001b[39m.\u001b[39msave_checkpoint(ckpt_dir\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_dir,\n\u001b[1;32m    610\u001b[0m                             target\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: state\u001b[39m.\u001b[39mparams,\n\u001b[1;32m    611\u001b[0m                                     \u001b[39m'\u001b[39m\u001b[39mbatch_stats\u001b[39m\u001b[39m'\u001b[39m: state\u001b[39m.\u001b[39mbatch_stats},\n\u001b[1;32m    612\u001b[0m                             step\u001b[39m=\u001b[39mstep,\n\u001b[1;32m    613\u001b[0m                             overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m                             )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'checkpoints' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.train_model(model, state, train_loader=train_loader, val_loader=val_loader, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataset:\n",
    "    x, y = batch\n",
    "    print( y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6250"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp                # JAX NumPy\n",
    "\n",
    "from flax import linen as nn           # The Linen API\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "import numpy as np                     # Ordinary NumPy\n",
    "import optax                           # Optimizers\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  \"\"\"A simple CNN model.\"\"\"\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    x = x.reshape((x.shape[0], -1))  # flatten\n",
    "    x = nn.Dense(features=256)(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.Dense(features=10)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def cross_entropy_loss(*, logits, labels):\n",
    "\n",
    "  labels_onehot = jax.nn.one_hot(labels, num_classes=10)\n",
    "  return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()\n",
    "\n",
    "\n",
    "def compute_metrics(*, logits, labels):\n",
    "\n",
    "  loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "  metrics = {\n",
    "      'loss': loss,\n",
    "      'accuracy': accuracy,\n",
    "  }\n",
    "  return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(rng, learning_rate, momentum):\n",
    "  \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "  cnn = CNN()\n",
    "  params = cnn.init(rng, next(iter(train_loader))[0])['params']\n",
    "  tx = optax.sgd(learning_rate, momentum)\n",
    "  return train_state.TrainState.create(\n",
    "      apply_fn=cnn.apply, params=params, tx=tx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 2.3343, accuracy: 9.69\n",
      "elpased_time:  11.437186002731323\n",
      "train epoch: 2, loss: 2.3312, accuracy: 9.92\n",
      "elpased_time:  8.585633754730225\n",
      "train epoch: 3, loss: 2.3322, accuracy: 9.75\n",
      "elpased_time:  8.396543979644775\n",
      "train epoch: 4, loss: 2.3300, accuracy: 10.15\n",
      "elpased_time:  8.821658611297607\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb#X43sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m rng, input_rng \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39msplit(rng)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb#X43sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39m# Run an optimization step over a training batch\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb#X43sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m state \u001b[39m=\u001b[39m train_epoch(state, train_loader, batch_size, epoch, input_rng)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb#X43sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39m# Evaluate on the test set after each training epoch \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb#X43sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m test_loader:\n",
      "\u001b[1;32m/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb Cell 17\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(state, train_ds, batch_size, epoch, rng)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb#X43sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m batch_metrics \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb#X43sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_ds:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb#X43sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m   state, metrics \u001b[39m=\u001b[39m train_step(state, batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb#X43sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m   batch_metrics\u001b[39m.\u001b[39mappend(metrics)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gholamhossin/local/labs/jaxutil/FlaxTrainer/examples/cnn/notebook.ipynb#X43sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# compute mean of metrics across each batch in epoch.\u001b[39;00m\n",
      "File \u001b[0;32m~/local/labs/.labs/lib/python3.10/site-packages/flax/core/frozen_dict.py:159\u001b[0m, in \u001b[0;36mFrozenDict.tree_unflatten\u001b[0;34m(cls, _, data)\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[39m\"\"\"Flattens this FrozenDict.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m \u001b[39m  Returns:\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39m    A flattened version of this FrozenDict instance.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m   \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dict,), ()\n\u001b[0;32m--> 159\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtree_unflatten\u001b[39m(\u001b[39mcls\u001b[39m, _, data):\n\u001b[1;32m    161\u001b[0m   \u001b[39m# data is already deep copied due to tree map mechanism\u001b[39;00m\n\u001b[1;32m    162\u001b[0m   \u001b[39m# we can skip the deep copy in the constructor\u001b[39;00m\n\u001b[1;32m    163\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39mdata, __unsafe_skip_copy__\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  def loss_fn(params):\n",
    "    logits = CNN().apply({'params': params}, batch[0])\n",
    "    loss = cross_entropy_loss(logits=logits, labels=batch[1])\n",
    "    return loss, logits\n",
    "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "  (_, logits), grads = grad_fn(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  metrics = compute_metrics(logits=logits, labels=batch[1])\n",
    "  return state, metrics\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(params, batch):\n",
    "  logits = CNN().apply({'params': params}, batch[0])\n",
    "  return compute_metrics(logits=logits, labels=batch[1])\n",
    "\n",
    "\n",
    "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "  \"\"\"Train for a single epoch.\"\"\"\n",
    "  train_ds_size = len(train_ds)\n",
    "  steps_per_epoch = train_ds_size // batch_size\n",
    "\n",
    "  perms = jax.random.permutation(rng, train_ds_size)\n",
    "  perms = perms[:steps_per_epoch * batch_size]  # skip incomplete batch\n",
    "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "  batch_metrics = []\n",
    "  for batch in train_ds:\n",
    "    state, metrics = train_step(state, batch)\n",
    "    batch_metrics.append(metrics)\n",
    "\n",
    "  # compute mean of metrics across each batch in epoch.\n",
    "  batch_metrics_np = jax.device_get(batch_metrics)\n",
    "  epoch_metrics_np = {\n",
    "      k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "      for k in batch_metrics_np[0]}\n",
    "\n",
    "  print('train epoch: %d, loss: %.4f, accuracy: %.2f' % (\n",
    "      epoch, epoch_metrics_np['loss'], epoch_metrics_np['accuracy'] * 100))\n",
    "\n",
    "  return state\n",
    "\n",
    "\n",
    "def eval_model(params, test_ds):\n",
    "  \n",
    "  metrics = eval_step(params, test_ds)\n",
    "  metrics = jax.device_get(metrics)\n",
    "  summary = jax.tree_util.tree_map(lambda x: x.item(), metrics)\n",
    "  return summary['loss'], summary['accuracy']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "state = create_train_state(init_rng, learning_rate, momentum)\n",
    "del init_rng  # Must not be used anymore.\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "  t = time()\n",
    "  # Use a separate PRNG key to permute image data during shuffling\n",
    "  rng, input_rng = jax.random.split(rng)\n",
    "  # Run an optimization step over a training batch\n",
    "  state = train_epoch(state, train_loader, batch_size, epoch, input_rng)\n",
    "  # Evaluate on the test set after each training epoch \n",
    "  for batch in test_loader:\n",
    "    test_loss, test_accuracy = eval_model(state.params, batch)\n",
    "  #print(' test epoch: %d, loss: %.2f, accuracy: %.2f' % (\n",
    "  #    epoch, test_loss, test_accuracy * 100))\n",
    "  print(\"elpased_time: \", (time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.labs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7c17e30e529363162b4f2bd4620f627c628f84c34e1cd85cef9b92e26a024c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
