{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gholamhossin/local/labs/.labs/lib/python3.10/site-packages/chex/_src/pytypes.py:37: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  PyTreeDef = type(jax.tree_structure(None))\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "\n",
    "import optax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.shape[-1]\n",
    "\n",
    "    score = jnp.matmul(q, jnp.swapaxes(k, -2, -1))\n",
    "    socre = score / jnp.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        socre = jnp.where(mask ==0, -9e15, score)\n",
    "    \n",
    "    attention = nn.softmax(score, axis=-1)\n",
    "    values = jnp.matmul(attention, v)\n",
    "\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[-0.6613315   0.70056266]\n",
      " [ 0.08239268 -1.7793142 ]\n",
      " [-0.04378588  1.0965251 ]]\n",
      "K\n",
      " [[ 1.7257481   0.35568172]\n",
      " [ 1.3034704   1.2873708 ]\n",
      " [ 1.6871481  -0.5714404 ]]\n",
      "V\n",
      " [[ 1.5129997   1.1050899 ]\n",
      " [ 0.27949408 -0.46224892]\n",
      " [-1.1003422  -1.1437942 ]]\n",
      "Values\n",
      " [[ 0.40075538 -0.1672631 ]\n",
      " [-0.650403   -0.7712134 ]\n",
      " [ 0.45445058 -0.14728263]]\n",
      "Attention\n",
      " [[0.2453795  0.62314427 0.13147624]\n",
      " [0.15692098 0.02888096 0.8141981 ]\n",
      " [0.23855191 0.6749896  0.0864585 ]]\n"
     ]
    }
   ],
   "source": [
    "seq_len, d_k = 3, 2\n",
    "main_rng, rand1 = jax.random.split(jax.random.PRNGKey(42))\n",
    "qkv = jax.random.normal(rand1, (3, seq_len, d_k))\n",
    "q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "values, attention = scaled_dot_product(q, k, v)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"Values\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    embed_dim: int # Output dimension\n",
    "    num_heads: int # Number of parllel heads (h)\n",
    "\n",
    "    def setup(self):\n",
    "        self.qkv_proj = nn.Dense(\n",
    "            3*self.embed_dim,\n",
    "            kernel_init=nn.initializers.xavier_uniform(),\n",
    "            bias_init=nn.initializers.zeros\n",
    "        )\n",
    "\n",
    "        self.o_proj = nn.Dense(\n",
    "            self.embed_dim,\n",
    "            kernel_init=nn.initializers.xavier_uniform(),\n",
    "            bias_init=nn.initializers.zeros\n",
    "        )\n",
    "    \n",
    "    def __call__(self, x, mask=None):\n",
    "        batch_size, seq_len, embed_dim  = x.shape\n",
    "\n",
    "        qkv = self.qkv_proj(x)\n",
    "\n",
    "        # Seperate Q, K, V\n",
    "        qkv = qkv.reshape(batch_size, seq_len, self.num_heads, -1)\n",
    "        qkv = qkv.transpose(0, 2, 1, 3) # batch, num_heads, seq_len, Dims\n",
    "        q, k, v = jnp.split(qkv, 3, axis=-1)\n",
    "\n",
    "        # Determine value outputs\n",
    "        values, attention = scaled_dot_product(q, k, v, mask=mask)\n",
    "        values = values.transpose(0, 2, 1, 3) # batch, seq_len, num_heads, Dims\n",
    "        values = values.reshape(batch_size, seq_len, embed_dim)\n",
    "        o = self.o_proj(values)\n",
    "\n",
    "        return o, attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out (3, 16, 128) Attention (3, 4, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "## Test MultiheadAttention implementation\n",
    "# Example features as input\n",
    "main_rng, x_rng = jax.random.split(jax.random.PRNGKey(42))\n",
    "x = jax.random.normal(x_rng, (3, 16, 128))\n",
    "# Create attention\n",
    "mh_attn = MultiheadAttention(embed_dim=128, num_heads=4)\n",
    "# Initialize parameters of attention with random key and inputs\n",
    "main_rng, init_rng = jax.random.split(jax.random.PRNGKey(42))\n",
    "params = mh_attn.init(init_rng, x)['params']\n",
    "# Apply attention with parameters on the inputs\n",
    "out, attn = mh_attn.apply({'params': params}, x)\n",
    "print('Out', out.shape, 'Attention', attn.shape)\n",
    "\n",
    "del mh_attn, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d94d86e058144db95f98d45a5a7e8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8375039ca32d418f8a8db176e221dfee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/mrpc (download: 1.43 MiB, generated: 1.43 MiB, post-processed: Unknown size, total: 2.85 MiB) to /home/gholamhossin/local/labs/.hugging_face/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:HF google storage unreachable. Downloading and preparing it from source\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524294257bcb47ab8688c46ef848380a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d144d92b576a442c8327abd4369173af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95963e1399bc40d7b2079f3fcda05e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93e4b3741dd4b0faa05157a626a2436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac7962554ab4c9d8472337ffc9e585e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e660c60137472cb35dde75daa439f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bf49eef3564657b1fb1435f355e488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /home/gholamhossin/local/labs/.hugging_face/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"glue\", \"mrpc\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb7c4036b5a4abf9f629a55e2f35605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f98f123022643f0a72a6be9534eea7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading flax_model.msgpack:   0%|          | 0.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing FlaxBertForSequenceClassification: {('cls', 'predictions', 'transform', 'LayerNorm', 'scale'), ('cls', 'predictions', 'bias'), ('cls', 'predictions', 'transform', 'dense', 'kernel'), ('cls', 'predictions', 'transform', 'dense', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'bias')}\n",
      "- This IS expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: {('classifier', 'kernel'), ('bert', 'pooler', 'dense', 'kernel'), ('bert', 'pooler', 'dense', 'bias'), ('classifier', 'bias')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import FlaxAutoModelForSequenceClassification, AutoTokenizer\n",
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "ds = dataset.with_format('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': <tf.Tensor: shape=(), dtype=string, numpy=b'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'>,\n",
       " 'sentence2': <tf.Tensor: shape=(), dtype=string, numpy=b'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'>,\n",
       " 'label': <tf.Tensor: shape=(), dtype=int64, numpy=1>,\n",
       " 'idx': <tf.Tensor: shape=(), dtype=int64, numpy=0>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.labs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7c17e30e529363162b4f2bd4620f627c628f84c34e1cd85cef9b92e26a024c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
